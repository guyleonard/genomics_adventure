# Task 3 - 
## Randomly Sampling your Data and Digital Normalisation
Sometimes you may find that you have sequenced too much data! This is not a bad place to be in, but it may put limits on your infrastructure - if you have too much data, for example, your computer may not be able to keep it all in memory to assemble it.

There are two methods of reducing your data:

### 1. Random Sampling

### 2. Digital Normalisation

## Contaminant Checking
A number of tools are available which also enable to you to quickly search through your reads and assign them to particular taxa or taxonomic group. These can serve as a quick check to make sure your samples or libraries are not contaminated with DNA from other sources. If you are performing a de-novo assembly, for example, and have DNA sequences present from multiple organisms, you will risk poor results and chimeric contigs.

Some ‘contaminants’ may turn out to be inevitable by-products of sampling and DNA extraction, and this is often the case with algae, and/or other symbionts but some groups have made amazing discoveries such as the discovery of a third symbiont (which turned out to be a yeast) in lichen, [here](http://science.sciencemag.org/content/353/6298/488.full).

Some tools you can use to check the taxonomic classification of reads include:
 * [Kraken](https://ccb.jhu.edu/software/kraken2/)
 * [Centrifuge](https://ccb.jhu.edu/software/centrifuge/)
 * [Blobology](https://blobtoolkit.genomehubs.org/)
 * Blast (in conjunction with sub-sampling your reads) and Krona to plot results
 * and many more!

# [Task 4]()
